# Surrogate time series
y_m_list <- sort(unique(df_summary$month))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for(i in seq_along(y_m_list)){
res_ym <- y_m_list[i]
tilde_y_m[i,] <- df_summary[df_summary$month == res_ym, "aveScore", drop = TRUE]
}
unem <- df_new %>%
group_by(month) %>%
summarise(y = mean(unem, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
unem <- scale(unem)
h_pred <- seq(8,15,1)
nf_files <- file.path("nf_results", paste0("no_unem_h", h_pred, ".json"))
if (!all(file.exists(nf_files))) {
stop("Missing nf_results/no_unem_h*.json files; run run_nf_gpu_all.sh first.")
}
nf_list <- lapply(nf_files, jsonlite::fromJSON)
Res_m <- matrix(nrow = length(h_pred), ncol = 20)
for(k in seq_along(h_pred)){
h <- h_pred[k]
res_c <- NULL
test_idx <- (length(y) - h + 1):length(y)
obs_idx <- setdiff(seq_along(y), test_idx)
# AR
ar_base <- tryCatch(auto.arima(y[obs_idx],max.q = 0, D = 0,seasonal = FALSE, allowmean = FALSE, allowdrift = FALSE),
error = function(e) list(arma = c(1,0,0)))
ar_fit <- arima(y[obs_idx], order = c(ar_base$arma[1],0,0), include.mean = FALSE)
ar_prediction <- predict(ar_fit, n.ahead = h)$pred
res_c <- c(res_c, sqrt(mean((ar_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(ar_prediction) !=sign(y[test_idx])))
#random walk
mean_prediction <- rep(y[max(obs_idx)], length(test_idx))
res_c <- c(res_c, sqrt(mean((mean_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(mean_prediction) !=sign(y[test_idx])))
#Average
ave_prediction <- Average_prediction(y[obs_idx], length(test_idx))
res_c <- c(res_c, sqrt(mean((ave_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(ave_prediction) !=sign(y[test_idx])))
#AR + unemployment
ar_unem_base <- tryCatch(auto.arima(y[obs_idx], xreg = unem[obs_idx], max.q = 0, D = 0,seasonal = FALSE, allowmean = FALSE,      allowdrift = FALSE),
error = function(e) list(arma = c(1,0,0)))
ar_unem_fit <- arima(y[obs_idx], xreg = unem[obs_idx], order = c(ar_unem_base$arma[1],0,0), include.mean = FALSE)
ar_unem_prediction <- predict(ar_unem_fit, newxreg = unem[test_idx], n.ahead = h)$pred
res_c <- c(res_c, sqrt(mean((ar_unem_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(ar_unem_prediction) !=sign(y[test_idx])))
#AR + LDA embedding
arx_fit <- arima(y[obs_idx], order = c(ar_base$arma[1],0,0), xreg = X_m[obs_idx,strong_idx, drop = FALSE], include.mean = FALSE)
arx_predictions <- predict(arx_fit, n.ahead = h, newxreg = X_m[test_idx,strong_idx, drop = FALSE])$pred
res_c <- c(res_c, sqrt(mean((arx_predictions-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(arx_predictions) !=sign(y[test_idx])))
# AR + unem + LDA embedding
arx_unem_fit <- arima(y[obs_idx],order = c(max(1, ar_base$arma[1]),0,0), xreg = cbind(X_m[obs_idx,strong_idx, drop=FALSE],unem[obs_idx]),    include.mean = FALSE)
arx_unem_predictions <-predict(arx_unem_fit, n.ahead=h, newxreg=cbind(X_m[test_idx,strong_idx,drop=FALSE],  unem[test_idx]))$pred
res_c <- c(res_c, sqrt(mean((arx_unem_predictions-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(arx_unem_predictions) !=sign(y[test_idx])))
# LLM powered: lag term + LDA embedding
p1=ar_base$arma[1]
p2=1
powered_prediction <- LLM_TS.Predict(X_m, y, tilde_y_m, p1, p2, obs_idx, test_idx, strong_idx, h)
res_c <- c(res_c, sqrt(mean((powered_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(powered_prediction) !=sign(y[test_idx])))
# LLM powered: lag term + unem + LDA embedding
powered_unem_prediction <- LLM_TS.Predict(cbind(X_m,unem), y, tilde_y_m, p1, p2, obs_idx, test_idx,
c(strong_idx,ncol(X_m)+1), h)
res_c <- c(res_c, sqrt(mean((powered_unem_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(powered_unem_prediction) !=sign(y[test_idx])))
# TimeLLM (CPI only)
time_llm_prediction <- nf_list[[k]]$results$TimeLLM$pred
res_c <- c(res_c, sqrt(mean((time_llm_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(time_llm_prediction) !=sign(y[test_idx])))
# PatchTST (CPI only)
patchtst_prediction <- nf_list[[k]]$results$PatchTST$pred
res_c <- c(res_c, sqrt(mean((patchtst_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(patchtst_prediction) !=sign(y[test_idx])))
Res_m[k,] <- res_c
}
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- tryCatch(select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 0.1),
error = function(e) list(selected = character()))
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
strong_idx
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./lda_revise.csv")
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./lda_revise.csv")
df$X3 <- sample(X3)
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./lda_revise.csv")
df$X3 <- sample(df$X3)
df$X4 <- sample(df$X4)
# identify topic and unemployment columns from the new file schema
topic_cols <- names(df)[grepl("^X\\d+$|^\\d+$", names(df))]
stopifnot("No topic columns found" = length(topic_cols) > 0)
unem_col <- "unem"
has_unem <- TRUE
# tidy with month/period
df_new <- df %>%
mutate(
time = as.Date(time),
unem = .data[[unem_col]],
cpi = cpi_lastmonth_100,
month = format(time, "%Y-%m"),
day = lubridate::day(time),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
) %>%
select(month, period, aveScore, all_of(topic_cols), unem, cpi)
# monthly-period means
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
y_m_list <- sort(unique(df_summary$month))
month_dates <- as.Date(paste0(y_m_list, "-01"))
# topics (month averages)
topic_cols_summary <- intersect(topic_cols, names(df_summary))
X_m <- df_summary %>%
group_by(month) %>%
summarise(across(all_of(topic_cols_summary), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
arrange(month) %>%
select(-month) %>%
as.matrix()
X_m <- scale(X_m)
# CPI and unemployment (month averages, scaled)
y <- df_new %>%
group_by(month) %>%
summarise(y = mean(cpi, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
y <- scale(y - 100)
# Surrogate time series
y_m_list <- sort(unique(df_summary$month))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for(i in seq_along(y_m_list)){
res_ym <- y_m_list[i]
tilde_y_m[i,] <- df_summary[df_summary$month == res_ym, "aveScore", drop = TRUE]
}
unem <- df_new %>%
group_by(month) %>%
summarise(y = mean(unem, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
unem <- scale(unem)
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- tryCatch(select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 0.1),
error = function(e) list(selected = character()))
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
strong_idx
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./lda_revise.csv")
#df$X3 <- sample(df$X3)
df$X4 <- sample(df$X4)
# identify topic and unemployment columns from the new file schema
topic_cols <- names(df)[grepl("^X\\d+$|^\\d+$", names(df))]
stopifnot("No topic columns found" = length(topic_cols) > 0)
unem_col <- "unem"
has_unem <- TRUE
# tidy with month/period
df_new <- df %>%
mutate(
time = as.Date(time),
unem = .data[[unem_col]],
cpi = cpi_lastmonth_100,
month = format(time, "%Y-%m"),
day = lubridate::day(time),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
) %>%
select(month, period, aveScore, all_of(topic_cols), unem, cpi)
# monthly-period means
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
y_m_list <- sort(unique(df_summary$month))
month_dates <- as.Date(paste0(y_m_list, "-01"))
# topics (month averages)
topic_cols_summary <- intersect(topic_cols, names(df_summary))
X_m <- df_summary %>%
group_by(month) %>%
summarise(across(all_of(topic_cols_summary), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
arrange(month) %>%
select(-month) %>%
as.matrix()
X_m <- scale(X_m)
# CPI and unemployment (month averages, scaled)
y <- df_new %>%
group_by(month) %>%
summarise(y = mean(cpi, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
y <- scale(y - 100)
# Surrogate time series
y_m_list <- sort(unique(df_summary$month))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for(i in seq_along(y_m_list)){
res_ym <- y_m_list[i]
tilde_y_m[i,] <- df_summary[df_summary$month == res_ym, "aveScore", drop = TRUE]
}
unem <- df_new %>%
group_by(month) %>%
summarise(y = mean(unem, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
unem <- scale(unem)
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- tryCatch(select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 0.1),
error = function(e) list(selected = character()))
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
strong_idx
df <- read.csv('./lda_revise.csv')
df$X3[2:nrow(X3)] <- df$X3[1:(nrow(X3)-1)]
View(df)
df$X3[2:nrow(df)] <- df$X3[1:(nrow(df)-1)]
View(df)
df$X3[1]
df$X3[1] <- df$X3[1] + runif(max=0.001)
runif(max=0.001)
runif(1,max=0.001)
unif(1,min = 0.001,max=0.005)
runif(1,min = 0.001,max=0.005)
df$X3[2:nrow(df)] <- df$X3[1:(nrow(df)-1)]
df$X3[1] <- df$X3[1] - runif(1,min = 0.001,max=0.005)
df$X4[2:nrow(df)] <- df$X4[1:(nrow(df)-1)]
df$X4[1] <- df$X4[1] - runif(1,min = 0.001,max=0.005)
knitr::opts_chunk$set(echo = TRUE)
# setwd("/Users/sunao/Desktop/LLM-TS-Revision/code/real_data")
# setwd("/Users/sunao/Desktop/LLM-TS-Revision/code/real_data/Weibo-final/")
source("./utility.R")
library(lubridate)
set.seed(2025)
# simple helpers used later in the Rmd
Average_prediction <- function(y, H) {
sapply(seq_len(H), function(h) mean(tail(y, h)))
}
check_coverage <- function(interval_row, true_val) {
as.integer(true_val >= interval_row[1] & true_val <= interval_row[2])
}
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./lda_revise.csv")
df$X3[2:nrow(df)] <- df$X3[1:(nrow(df)-1)]
df$X3[1] <- df$X3[1] - runif(1,min = 0.001,max=0.005)
df$X4[2:nrow(df)] <- df$X4[1:(nrow(df)-1)]
df$X4[1] <- df$X4[1] - runif(1,min = 0.001,max=0.005)
# identify topic and unemployment columns from the new file schema
topic_cols <- names(df)[grepl("^X\\d+$|^\\d+$", names(df))]
stopifnot("No topic columns found" = length(topic_cols) > 0)
unem_col <- "unem"
has_unem <- TRUE
# tidy with month/period
df_new <- df %>%
mutate(
time = as.Date(time),
unem = .data[[unem_col]],
cpi = cpi_lastmonth_100,
month = format(time, "%Y-%m"),
day = lubridate::day(time),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
) %>%
select(month, period, aveScore, all_of(topic_cols), unem, cpi)
# monthly-period means
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
y_m_list <- sort(unique(df_summary$month))
month_dates <- as.Date(paste0(y_m_list, "-01"))
# topics (month averages)
topic_cols_summary <- intersect(topic_cols, names(df_summary))
X_m <- df_summary %>%
group_by(month) %>%
summarise(across(all_of(topic_cols_summary), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
arrange(month) %>%
select(-month) %>%
as.matrix()
X_m <- scale(X_m)
# CPI and unemployment (month averages, scaled)
y <- df_new %>%
group_by(month) %>%
summarise(y = mean(cpi, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
y <- scale(y - 100)
# Surrogate time series
y_m_list <- sort(unique(df_summary$month))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for(i in seq_along(y_m_list)){
res_ym <- y_m_list[i]
tilde_y_m[i,] <- df_summary[df_summary$month == res_ym, "aveScore", drop = TRUE]
}
unem <- df_new %>%
group_by(month) %>%
summarise(y = mean(unem, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
unem <- scale(unem)
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- tryCatch(select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 0.1),
error = function(e) list(selected = character()))
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
strong_idx
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- tryCatch(select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 1),
error = function(e) list(selected = character()))
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
strong_idx
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- tryCatch(select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 10),
error = function(e) list(selected = character()))
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
strong_idx
knitr::opts_chunk$set(echo = TRUE)
# setwd("/Users/sunao/Desktop/LLM-TS-Revision/code/real_data")
# setwd("/Users/sunao/Desktop/LLM-TS-Revision/code/real_data/Weibo-final/")
source("./utility.R")
library(lubridate)
set.seed(2025)
# simple helpers used later in the Rmd
Average_prediction <- function(y, H) {
sapply(seq_len(H), function(h) mean(tail(y, h)))
}
check_coverage <- function(interval_row, true_val) {
as.integer(true_val >= interval_row[1] & true_val <= interval_row[2])
}
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./lda_revise.csv")
# identify topic and unemployment columns from the new file schema
topic_cols <- names(df)[grepl("^X\\d+$|^\\d+$", names(df))]
stopifnot("No topic columns found" = length(topic_cols) > 0)
unem_col <- "unem"
has_unem <- TRUE
# tidy with month/period
df_new <- df %>%
mutate(
time = as.Date(time),
unem = .data[[unem_col]],
cpi = cpi_lastmonth_100,
month = format(time, "%Y-%m"),
day = lubridate::day(time),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
) %>%
select(month, period, aveScore, all_of(topic_cols), unem, cpi)
# monthly-period means
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
y_m_list <- sort(unique(df_summary$month))
month_dates <- as.Date(paste0(y_m_list, "-01"))
# topics (month averages)
topic_cols_summary <- intersect(topic_cols, names(df_summary))
X_m <- df_summary %>%
group_by(month) %>%
summarise(across(all_of(topic_cols_summary), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
arrange(month) %>%
select(-month) %>%
as.matrix()
X_m <- scale(X_m)
# CPI and unemployment (month averages, scaled)
y <- df_new %>%
group_by(month) %>%
summarise(y = mean(cpi, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
y <- scale(y - 100)
# Surrogate time series
y_m_list <- sort(unique(df_summary$month))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for(i in seq_along(y_m_list)){
res_ym <- y_m_list[i]
tilde_y_m[i,] <- df_summary[df_summary$month == res_ym, "aveScore", drop = TRUE]
}
unem <- df_new %>%
group_by(month) %>%
summarise(y = mean(unem, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
unem <- scale(unem)
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- tryCatch(select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 0.1),
error = function(e) list(selected = character()))
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
strong_idx
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./IE_CPI_Unemp_lda45_2019_202509_20251114.csv")
knitr::opts_chunk$set(echo = TRUE)
# setwd("/Users/sunao/Desktop/LLM-TS-Revision/code/real_data")
# setwd("/Users/sunao/Desktop/LLM-TS-Revision/code/real_data/Weibo-final/")
source("./utility.R")
library(lubridate)
set.seed(2025)
# simple helpers used later in the Rmd
Average_prediction <- function(y, H) {
sapply(seq_len(H), function(h) mean(tail(y, h)))
}
check_coverage <- function(interval_row, true_val) {
as.integer(true_val >= interval_row[1] & true_val <= interval_row[2])
}
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./IE_CPI_Unemp_lda45_2019_202509_20251114.csv")
# identify topic and unemployment columns from the new file schema
topic_cols <- names(df)[grepl("^X\\d+$|^\\d+$", names(df))]
stopifnot("No topic columns found" = length(topic_cols) > 0)
unem_col <- "unem"
has_unem <- TRUE
# tidy with month/period
df_new <- df %>%
mutate(
time = as.Date(time),
unem = .data[[unem_col]],
cpi = cpi_lastmonth_100,
month = format(time, "%Y-%m"),
day = lubridate::day(time),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
) %>%
select(month, period, aveScore, all_of(topic_cols), unem, cpi)
# read the LDA embedding dataset (new files live in lda_manyTopics/)
df <- read.csv("./IE_CPI_Unemp_lda45_2019_202509_20251114.csv")
# identify topic and unemployment columns from the new file schema
topic_cols <- names(df)[grepl("^X\\d+$|^\\d+$", names(df))]
stopifnot("No topic columns found" = length(topic_cols) > 0)
unem_col <- "unem"
has_unem <- TRUE
# tidy with month/period
df_new <- df %>%
mutate(
time = as.Date(time),
unem = .data[[unem_col]],
cpi = cpi_lastmonth_100,
month = format(time, "%Y-%m"),
day = lubridate::day(time),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
) %>%
select(month, period, aveScore, all_of(topic_cols), unem, cpi)
# monthly-period means
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
y_m_list <- sort(unique(df_summary$month))
month_dates <- as.Date(paste0(y_m_list, "-01"))
# topics (month averages)
topic_cols_summary <- intersect(topic_cols, names(df_summary))
X_m <- df_summary %>%
group_by(month) %>%
summarise(across(all_of(topic_cols_summary), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
arrange(month) %>%
select(-month) %>%
as.matrix()
#X_m <- scale(X_m)
# CPI and unemployment (month averages, scaled)
y <- df_new %>%
group_by(month) %>%
summarise(y = mean(cpi, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
y <- scale(y)
#y <- (y - 100)
#y <- scale(y - 100)
# Surrogate time series
y_m_list <- sort(unique(df_summary$month))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for(i in seq_along(y_m_list)){
res_ym <- y_m_list[i]
tilde_y_m[i,] <- df_summary[df_summary$month == res_ym, "aveScore", drop = TRUE]
}
unem <- df_new %>%
group_by(month) %>%
summarise(y = mean(unem, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
unem <- scale(unem)
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- tryCatch(select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 0.1),
error = function(e) list(selected = character()))
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
strong_idx
