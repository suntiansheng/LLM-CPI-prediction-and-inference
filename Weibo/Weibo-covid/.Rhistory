mutate(d = d, eta = eta, nsim = nsim) %>%
select(d, eta, nsim, model, coverage, se_coverage, avg_length, se_length)
}
run_simulation <- function(d_vals = c(10, 50, 100, 200, 500),
eta_vals = c(0.1, 0.2, 0.3, 0.4, 0.5),
n = 500,
nsim = 1000,
alpha = 0.05,
seed = 20250314) {
set.seed(seed)
params <- expand.grid(d = d_vals, eta = eta_vals, KEEP.OUT.ATTRS = FALSE)
results <- purrr::pmap_dfr(
list(params$d, params$eta),
~ simulate_setting(d = ..1, eta = ..2, n = n, nsim = nsim, alpha = alpha)
)
results
}
# -----------------------------------------------------------------------------#
# Run the full grid of simulations and print the summary table
# -----------------------------------------------------------------------------#
simulation_results <- run_simulation()
library(dplyr)
library(tidyr)
simulate_setting <- function(d,
eta,
n = 500,
nsim = 1000,
alpha = 0.05) {
# Storage vectors
cov_m1 <- len_m1 <- numeric(nsim)
cov_m2 <- len_m2 <- numeric(nsim)
cov_m3 <- len_m3 <- numeric(nsim)
for (s in seq_len(nsim)) {
# --- Training sample ------------------------------------------------------
x  <- rnorm(n)
z  <- matrix(rnorm(n * d), nrow = n, ncol = d)
z_sum <- rowSums(z)
eps  <- rnorm(n)
v    <- rnorm(n)
epsS <- eta * eps + sqrt(1 - eta^2) * v
y  <- x + eps
ys <- z_sum + x + epsS
train <- data.frame(y = y, x = x, ys = ys, epsS = epsS)
# Fit models
fit_m1 <- lm(y ~ x-1, data = train)
fit_m2 <- lm(y ~ x + ys-1, data = train)
fit_m3 <- lm(y ~ x + epsS-1, data = train)
# --- New observation ------------------------------------------------------
x_new   <- rnorm(1)
z_new   <- rnorm(d)
zsum_new <- sum(z_new)
eps_new <- rnorm(1)
v_new   <- rnorm(1)
epsS_new <- eta * eps_new + sqrt(1 - eta^2) * v_new
y_new  <- x_new + eps_new
ys_new <- zsum_new + x_new + epsS_new
newdata_m1 <- data.frame(x = x_new)
newdata_m2 <- data.frame(x = x_new, ys = ys_new)
newdata_m3 <- data.frame(x = x_new, epsS = epsS_new)
# Prediction intervals
pred_m1 <- predict(fit_m1, newdata = newdata_m1,
interval = "prediction", level = 1 - alpha)
pred_m2 <- predict(fit_m2, newdata = newdata_m2,
interval = "prediction", level = 1 - alpha)
pred_m3 <- predict(fit_m3, newdata = newdata_m3,
interval = "prediction", level = 1 - alpha)
# Coverage + length
cov_m1[s] <- as.integer(y_new >= pred_m1[1, "lwr"] && y_new <= pred_m1[1, "upr"])
len_m1[s] <- pred_m1[1, "upr"] - pred_m1[1, "lwr"]
cov_m2[s] <- as.integer(y_new >= pred_m2[1, "lwr"] && y_new <= pred_m2[1, "upr"])
len_m2[s] <- pred_m2[1, "upr"] - pred_m2[1, "lwr"]
cov_m3[s] <- as.integer(y_new >= pred_m3[1, "lwr"] && y_new <= pred_m3[1, "upr"])
len_m3[s] <- pred_m3[1, "upr"] - pred_m3[1, "lwr"]
}
summarize_model <- function(coverage, length) {
tibble(
coverage = mean(coverage),
#se_coverage = sd(coverage) / sqrt(nsim),
avg_length = mean(length),
#se_length = sd(length) / sqrt(nsim)
)
}
bind_rows(
summarize_model(cov_m1, len_m1) %>% mutate(model = "y ~ x"),
summarize_model(cov_m2, len_m2) %>% mutate(model = "y ~ x + y_s"),
summarize_model(cov_m3, len_m3) %>% mutate(model = "y ~ x + epsilon_s")
) %>%
mutate(d = d, eta = eta, nsim = nsim) %>%
select(d, eta, nsim, model, coverage, se_coverage, avg_length, se_length)
}
run_simulation <- function(d_vals = c(10, 50, 100, 200, 500),
eta_vals = c(0.1, 0.2, 0.3, 0.4, 0.5),
n = 500,
nsim = 1000,
alpha = 0.05,
seed = 20250314) {
set.seed(seed)
params <- expand.grid(d = d_vals, eta = eta_vals, KEEP.OUT.ATTRS = FALSE)
results <- purrr::pmap_dfr(
list(params$d, params$eta),
~ simulate_setting(d = ..1, eta = ..2, n = n, nsim = nsim, alpha = alpha)
)
results
}
simulation_results <- run_simulation()
rlang::last_trace()
#!/usr/bin/env Rscript
# -----------------------------------------------------------------------------
# Prediction-interval comparison under correlated proxy information
#
# Data-generating mechanism:
#   x        ~ N(0, 1)
#   z_j      ~ N(0, 1)  (independent, j = 1, ..., d)
#   epsilon  ~ N(0, 1)
#   epsilonS ~ N(0, 1)
#   Corr(epsilon, epsilonS) = eta
#
# Responses:
#   y   = x + epsilon
#   ys  = (sum_{j=1}^d z_j) + x + epsilonS   # scalar auxiliary measurement
#
# Models compared (all include an intercept):
#   M1: y ~ x
#   M2: y ~ x + ys
#   M3: y ~ x + epsilonS
#
# For each combination of:
#   d    in {10, 50, 100, 200, 500}
#   eta  in {0.1, 0.2, 0.3, 0.4, 0.5}
#
# we generate n = 500 training observations, fit the three models,
# and evaluate 95% t-based prediction intervals on a fresh test point
# (drawn from the same mechanism). We run nsim = 1000 Monte Carlo replications
# per (d, eta) pair, recording empirical coverage and average interval length.
#
# Output: a summary data frame printed to the console.
# -----------------------------------------------------------------------------
suppressPackageStartupMessages({
library(dplyr)
library(tidyr)
library(purrr)
})
simulate_setting <- function(d,
eta,
n = 500,
nsim = 1000,
alpha = 0.05) {
cov_m1 <- len_m1 <- numeric(nsim)
cov_m2 <- len_m2 <- numeric(nsim)
cov_m3 <- len_m3 <- numeric(nsim)
for (s in seq_len(nsim)) {
# --- Training sample ------------------------------------------------------
x      <- rnorm(n)
z      <- matrix(rnorm(n * d), nrow = n, ncol = d)
z_sum  <- rowSums(z)
eps    <- rnorm(n)
v      <- rnorm(n)
epsS   <- eta * eps + sqrt(1 - eta^2) * v
y      <- x + eps
ys     <- z_sum + x + epsS
train  <- data.frame(y = y, x = x, ys = ys, epsS = epsS)
# Fit models (with intercepts)
fit_m1 <- lm(y ~ x, data = train)
fit_m2 <- lm(y ~ x + ys, data = train)
fit_m3 <- lm(y ~ x + epsS, data = train)
# --- New observation ------------------------------------------------------
x_new     <- rnorm(1)
z_new     <- rnorm(d)
zsum_new  <- sum(z_new)
eps_new   <- rnorm(1)
v_new     <- rnorm(1)
epsS_new  <- eta * eps_new + sqrt(1 - eta^2) * v_new
y_new     <- x_new + eps_new
ys_new    <- zsum_new + x_new + epsS_new
newdata_m1 <- data.frame(x = x_new)
newdata_m2 <- data.frame(x = x_new, ys = ys_new)
newdata_m3 <- data.frame(x = x_new, epsS = epsS_new)
# Prediction intervals
pred_m1 <- predict(fit_m1, newdata = newdata_m1,
interval = "prediction", level = 1 - alpha)
pred_m2 <- predict(fit_m2, newdata = newdata_m2,
interval = "prediction", level = 1 - alpha)
pred_m3 <- predict(fit_m3, newdata = newdata_m3,
interval = "prediction", level = 1 - alpha)
# Coverage + length
cov_m1[s] <- as.numeric(y_new >= pred_m1[1, "lwr"] && y_new <= pred_m1[1, "upr"])
len_m1[s] <- pred_m1[1, "upr"] - pred_m1[1, "lwr"]
cov_m2[s] <- as.numeric(y_new >= pred_m2[1, "lwr"] && y_new <= pred_m2[1, "upr"])
len_m2[s] <- pred_m2[1, "upr"] - pred_m2[1, "lwr"]
cov_m3[s] <- as.numeric(y_new >= pred_m3[1, "lwr"] && y_new <= pred_m3[1, "upr"])
len_m3[s] <- pred_m3[1, "upr"] - pred_m3[1, "lwr"]
}
summarize_model <- function(coverage, length) {
tibble(
coverage    = mean(coverage),
se_coverage = sd(coverage) / sqrt(nsim),
avg_length  = mean(length),
se_length   = sd(length) / sqrt(nsim)
)
}
bind_rows(
summarize_model(cov_m1, len_m1) %>% mutate(model = "y ~ x"),
summarize_model(cov_m2, len_m2) %>% mutate(model = "y ~ x + y_s"),
summarize_model(cov_m3, len_m3) %>% mutate(model = "y ~ x + epsilon_s")
) %>%
mutate(d = d, eta = eta, nsim = nsim) %>%
select(d, eta, nsim, model, coverage, se_coverage, avg_length, se_length)
}
run_simulation <- function(d_vals = c(10, 50, 100, 200, 500),
eta_vals = c(0.1, 0.2, 0.3, 0.4, 0.5),
n = 500,
nsim = 1000,
alpha = 0.05,
seed = 20250314) {
set.seed(seed)
params <- expand.grid(d = d_vals, eta = eta_vals, KEEP.OUT.ATTRS = FALSE)
purrr::pmap_dfr(
list(params$d, params$eta),
~ simulate_setting(d = ..1, eta = ..2, n = n, nsim = nsim, alpha = alpha)
)
}
# -----------------------------------------------------------------------------
# Run the full grid of simulations and print the summary table
# -----------------------------------------------------------------------------
simulation_results <- run_simulation()
print(simulation_results, digits = 3)
View(simulation_results)
load("~/Desktop/res_rkhs_bootstrap.rds")
readRDS("~/Desktop/res_rkhs_bootstrap.rds")
readRDS("~/Desktop/res_yan2025.rds")
setwd("/Users/sunao/Desktop/code-release/Weibo/Weibo-covid")
setwd("/Users/sunao/Desktop/code-release/Weibo/Weibo-covid")
source('./utility.R')
library(dplyr)
library(forecast)
library(MTS)
############### 19-21 ##################
##new dataset
df <- read.csv('3year_meanTopic20Distri_mergeCPI_df19-21_20250314.csv')
colnames(df)
#3year_meanTopic20Distri_mergeCPI_df19-21_20250314.csv
#3year_meanTopic20Distri_mergeCPI_df21-23_20250314.csv
Top_num <- 20
colnames(df)
df_new <- df[,c(1,3,7:(Top_num+6))]
colnames(df_new)
df_new$unem <-df$全国城镇调查失业率...
df_new$cpi <- df$cpi_lastmonth_100
df_new$time <- as.Date(df_new$time)
df_new <- df_new %>%
arrange(time)
df_new <- df_new %>%
mutate(
month = format(time,"%Y-%m"),  # 提取年月
day = day(time),                # 提取日
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
)
df_new <- df_new[,!names(df_new) %in% c("time")]
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), mean, na.rm = TRUE))
df_new <- df_new %>%
mutate(
month = format(time,"%Y-%m"),  # 提取年月
day = day(time),                # 提取日
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
)
############### 19-21 ##################
##new dataset
df <- read.csv('3year_meanTopic20Distri_mergeCPI_df19-21_20250314.csv')
colnames(df)
#3year_meanTopic20Distri_mergeCPI_df19-21_20250314.csv
#3year_meanTopic20Distri_mergeCPI_df21-23_20250314.csv
Top_num <- 20
colnames(df)
df_new <- df[,c(1,3,7:(Top_num+6))]
colnames(df_new)
df_new$unem <-df$全国城镇调查失业率...
df_new$cpi <- df$cpi_lastmonth_100
df_new$time <- as.Date(df_new$time)
df_new <- df_new %>%
arrange(time)
df_new <- df_new %>%
mutate(
month = format(time,"%Y-%m"),  # 提取年月
day = day(time),                # 提取日
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
)
df_new <- df_new[,!names(df_new) %in% c("time")]
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), mean, na.rm = TRUE))
y_m_list <- sort(unique(df_summary$month))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for(i in 1:length(y_m_list)){
res_ym <- y_m_list[i]
tilde_y_m[i,] <- df_summary[df_summary$month == res_ym,]$pred_scoreInflation
}
tilde_y_m <- scale(tilde_y_m-0.5, center = FALSE)
X_m <- matrix(ncol = Top_num, nrow = length(y_m_list))
for(i in 1:length(y_m_list)){
res_ym <- y_m_list[i]
X_m[i,] <- apply(df_summary[df_summary$month == res_ym,4:(Top_num+3)],2,mean)
}
X_m <- scale(X_m, scale = FALSE)
y_df <- df_new %>%
group_by(month) %>%
summarise(y = mean(cpi))
y = y_df$y
y = y-100
y = scale(y,center = FALSE)
#############################################################################
#############################################################################
set.seed(1234)
h_c <- seq(2,6,1)
res_c <- NULL
rank_c <- NULL
for(k in 1:length(h_c)){
h <- h_c[k]
test_idx <- (length(y)-h+1):length(y)
obs_idx <- setdiff(1:length(y), test_idx)
ar_fit <- auto.arima(y[obs_idx], max.q = 0, D = 0,seasonal = FALSE, allowmean = FALSE, allowdrift = FALSE)
ar_fit <- arima(y[obs_idx], order = c(ar_fit$arma[1],0,0), include.mean = FALSE)
ar_prediction <- predict(ar_fit, n.ahead = h)$pred
mse_c <- NULL
for(i in 1:Top_num){
strong_idx <- order(abs(cov(ar_fit$residuals, X_m[obs_idx,])), decreasing = TRUE)[1:i]
arx_fit <- arima(y[obs_idx], order = c(ar_fit$arma[1],0,0), xreg = X_m[obs_idx,strong_idx], include.mean = FALSE)
arx_predictions <- predict(arx_fit, n.ahead = h, newxreg = X_m[test_idx,strong_idx])$pred
mse_c[i] <- mean((arx_predictions-y[test_idx])^2)
}
rank_c[k] <- which.min(mse_c)
}
names(which.max(table(rank_c)))
num_topic <- as.numeric(names(which.max(table(rank_c))))
strong_idx <- order(abs(cov(ar_fit$residuals, X_m[obs_idx,])), decreasing = TRUE)[1:num_topic]
#h_c <- seq(8,15,1)
set.seed(1234)
Res_m <- matrix(nrow = length(h_c), ncol = 11)
for(k in 1:length(h_c)){
h <- h_c[k]
res_c <- NULL
test_idx <- (length(y)-h+1):length(y)
obs_idx <- setdiff(1:length(y), test_idx)
#AR
ar_fit <- auto.arima(y[obs_idx],max.q = 0, D = 0,seasonal = FALSE, allowmean = FALSE, allowdrift = FALSE)
ar_fit <- arima(y[obs_idx], order = c(ar_fit$arma[1],0,0), include.mean = FALSE)
ar_prediction <- predict(ar_fit, n.ahead = h)$pred
res_c <- c(res_c, mean((ar_prediction-y[test_idx])^2))
res_c <- c(res_c, mean(sign(ar_prediction) !=sign(y[test_idx])))
#random walk
mean_prediction <- rep(y[max(obs_idx)], length(test_idx))
res_c <- c(res_c, sqrt(mean((mean_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(mean_prediction) !=sign(y[test_idx])))
#Average
ave_prediction <- Average_prediction(y[obs_idx], length(test_idx))
res_c <- c(res_c, sqrt(mean((ave_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(ave_prediction) !=sign(y[test_idx])))
#LDA
arx_fit <- arima(y[obs_idx], order = c(ar_fit$arma[1],0,0), xreg = X_m[obs_idx,strong_idx], include.mean = FALSE)
arx_predictions <- predict(arx_fit, n.ahead = h, newxreg = X_m[test_idx,strong_idx])$pred
res_c <- c(res_c, mean((arx_predictions-y[test_idx])^2))
res_c <- c(res_c, mean(sign(arx_predictions) !=sign(y[test_idx])))
# Power
p1=ar_fit$arma[1]
p2=1
powered_prediction <- Prediction_powered_ts(X_m, y, tilde_y_m, p1, p2, obs_idx, test_idx,
strong_idx, h)
res_c <- c(res_c, mean((powered_prediction-y[test_idx])^2))
res_c <- c(res_c, mean(sign(powered_prediction) !=sign(y[test_idx])))
Res_m[k,] <- c(h,res_c)
}
colnames(Res_m) <- c('h','ar_mse', 'ar_sign', 'RW_mse', 'RW_sign', 'AVE_mse','AVE_sign', 'LDA_mse', 'LDA_sign', 'LLM_LDA_mse','LLM_LDA_sign')
Res_m
#colMeans(Res_m)
#rbind(Res_m, colMeans(Res_m))
row.names(Res_m) <- Res_m[,1]
Res_m <- Res_m[,2:ncol(Res_m)]
Res_m[,seq(1,ncol(Res_m),2)]
Res_m[,seq(2,ncol(Res_m),2)]
df <- read.csv('3year_meanTopic20Distri_mergeCPI_df21-23_20250314.csv')
colnames(df)
#3year_meanTopic20Distri_mergeCPI_df19-21_20250314.csv
#3year_meanTopic20Distri_mergeCPI_df21-23_20250314.csv
Top_num <- 20
colnames(df)
df_new <- df[,c(1,3,7:(Top_num+6))]
colnames(df_new)
df_new$unem <-df$全国城镇调查失业率...
df_new$cpi <- df$cpi_lastmonth_100
df_new$time <- as.Date(df_new$time)
df_new <- df_new %>%
arrange(time)
df_new <- df_new %>%
mutate(
month = format(time,"%Y-%m"),  # 提取年月
day = day(time),                # 提取日
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
)
df_new <- df_new[,!names(df_new) %in% c("time")]
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), mean, na.rm = TRUE))
#max_num_day <- min(table(df_new$year_month))
y_m_list <- sort(unique(df_summary$month))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for(i in 1:length(y_m_list)){
res_ym <- y_m_list[i]
tilde_y_m[i,] <- df_summary[df_summary$month == res_ym,]$pred_scoreInflation
}
tilde_y_m <- scale(tilde_y_m-0.5, center = FALSE)
#ilde_y_m <- scale(tilde_y_m)
X_m <- matrix(ncol = Top_num, nrow = length(y_m_list))
for(i in 1:length(y_m_list)){
res_ym <- y_m_list[i]
X_m[i,] <- apply(df_summary[df_summary$month == res_ym,4:(Top_num+3)],2,mean)
}
X_m <- scale(X_m, scale = FALSE)
#X_lda <- X_m[,c(11,12)]
#write.csv(X_lda,file = 'lda_embedding.csv', row.names = FALSE)
y_df <- df_new %>%
group_by(month) %>%
summarise(y = mean(cpi))
y = y_df$y
y = y-100
y = scale(y,center = FALSE)
#tilde_y_fit <- VARX(zt = tilde_y_m, p=1, xt = X_m[,strong_idx], m=0, include.mean = FALSE)
#arx_fit <- arima(y, order = c(ar_fit$arma[1],0,0), xreg = X_m[,strong_idx], include.mean = FALSE)
#cor(cbind(arx_fit$residuals[2:length(arx_fit$residuals)],tilde_y_fit$residuals))
#############################################################################
#############################################################################
set.seed(1234)
h_c <- seq(2,6,1)
res_c <- NULL
rank_c <- NULL
for(k in 1:length(h_c)){
h <- h_c[k]
test_idx <- (length(y)-h+1):length(y)
obs_idx <- setdiff(1:length(y), test_idx)
ar_fit <- auto.arima(y[obs_idx], max.q = 0, D = 0,seasonal = FALSE, allowmean = FALSE, allowdrift = FALSE)
ar_fit <- arima(y[obs_idx], order = c(ar_fit$arma[1],0,0), include.mean = FALSE)
ar_prediction <- predict(ar_fit, n.ahead = h)$pred
mse_c <- NULL
for(i in 1:Top_num){
strong_idx <- order(abs(cor(ar_fit$residuals, X_m[obs_idx,])), decreasing = TRUE)[1:i]
arx_fit <- arima(y[obs_idx], order = c(ar_fit$arma[1],0,0), xreg = X_m[obs_idx,strong_idx], include.mean = FALSE)
arx_predictions <- predict(arx_fit, n.ahead = h, newxreg = X_m[test_idx,strong_idx])$pred
mse_c[i] <- mean((arx_predictions-y[test_idx])^2)
}
rank_c[k] <- which.min(mse_c)
}
names(which.max(table(rank_c)))
num_topic <- as.numeric(names(which.max(table(rank_c))))
strong_idx <- order(abs(cor(ar_fit$residuals, X_m[obs_idx,])), decreasing = TRUE)[1:num_topic]
# The final analysis
#h_c <- seq(8,15,1)
set.seed(1234)
Res_m <- matrix(nrow = length(h_c), ncol = 11)
for(k in 1:length(h_c)){
h <- h_c[k]
res_c <- NULL
test_idx <- (length(y)-h+1):length(y)
obs_idx <- setdiff(1:length(y), test_idx)
ar_fit <- auto.arima(y[obs_idx],max.q = 0, D = 0,seasonal = FALSE, allowmean = FALSE, allowdrift = FALSE)
ar_fit <- arima(y[obs_idx], order = c(ar_fit$arma[1],0,0), include.mean = FALSE)
ar_prediction <- predict(ar_fit, n.ahead = h)$pred
res_c <- c(res_c, mean((ar_prediction-y[test_idx])^2))
res_c <- c(res_c, mean(sign(ar_prediction) !=sign(y[test_idx])))
#random walk
mean_prediction <- rep(y[max(obs_idx)], length(test_idx))
res_c <- c(res_c, sqrt(mean((mean_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(mean_prediction) !=sign(y[test_idx])))
#Average
ave_prediction <- Average_prediction(y[obs_idx], length(test_idx))
res_c <- c(res_c, sqrt(mean((ave_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(ave_prediction) !=sign(y[test_idx])))
arx_fit <- arima(y[obs_idx], order = c(ar_fit$arma[1],0,0), xreg = X_m[obs_idx,strong_idx], include.mean = FALSE)
arx_predictions <- predict(arx_fit, n.ahead = h, newxreg = X_m[test_idx,strong_idx])$pred
res_c <- c(res_c, mean((arx_predictions-y[test_idx])^2))
res_c <- c(res_c, mean(sign(arx_predictions) !=sign(y[test_idx])))
p1=ar_fit$arma[1]
p2=1
powered_prediction <- Prediction_powered_ts(X_m, y, tilde_y_m, p1, p2, obs_idx, test_idx,
strong_idx, h)
res_c <- c(res_c, mean((powered_prediction-y[test_idx])^2))
res_c <- c(res_c, mean(sign(powered_prediction) !=sign(y[test_idx])))
Res_m[k,] <- c(h,res_c)
}
colnames(Res_m) <- c('h','ar_mse', 'ar_sign', 'RW_mse', 'RW_sign', 'AVE_mse','AVE_sign', 'LDA_mse', 'LDA_sign', 'LLM_LDA_mse','LLM_LDA_sign')
Res_m
#colMeans(Res_m)
#rbind(Res_m, colMeans(Res_m))
row.names(Res_m) <- Res_m[,1]
Res_m <- Res_m[,2:ncol(Res_m)]
Res_m[,seq(1,ncol(Res_m),2)]
Res_m[,seq(2,ncol(Res_m),2)]
