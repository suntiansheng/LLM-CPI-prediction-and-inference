period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
)
df_summary <- df %>%
group_by(month, period) %>%
summarise(across(everything(), \(x) mean(x, na.rm = TRUE)), .groups = "drop")
y_m_list <- sort(unique(df_summary$month))
month_dates <- as.Date(paste0(y_m_list, "-01"))
tilde_y_m <- matrix(ncol = 3, nrow = length(y_m_list))
for (i in seq_along(y_m_list)) {
res_ym <- y_m_list[i]
tilde_y_m[i, ] <- df_summary[df_summary$month == res_ym, ]$pred_score
}
#tilde_y_m <- scale(tilde_y_m)
topic_cols <- names(df_summary)[grepl("^topic", names(df_summary))]
X_m <- matrix(ncol = length(topic_cols), nrow = length(y_m_list))
for (i in seq_along(y_m_list)) {
res_ym <- y_m_list[i]
X_m[i, ] <- apply(df_summary[df_summary$month == res_ym, topic_cols], 2, mean)
}
X_m <- scale(X_m)
colnames(X_m) <- topic_cols
topic_dates <- df$date
topic_months <- df$month
unrate_monthly <- df %>%
group_by(month) %>%
summarise(unrate = mean(UNRATE, na.rm = TRUE), .groups = "drop") %>%
filter(month %in% y_m_list)
unem <- scale(unrate_monthly$unrate)
has_unem <- TRUE
m_dates <- macro_raw$sasdate
if (!target_var %in% names(macro_raw)) {
stop(paste("Target variable not found in 2025-10-MD.csv:", target_var))
}
m_vals <- macro_raw[[target_var]]
ptr <- 1
current <- NA_real_
target_series <- numeric(length(topic_dates))
for (i in seq_along(topic_dates)) {
t_d <- topic_dates[i]
while (ptr <= length(m_dates) && m_dates[ptr] <= t_d) {
current <- m_vals[ptr]
ptr <- ptr + 1
}
target_series[i] <- current
}
y_df <- data.frame(month = topic_months, y = target_series) %>%
group_by(month) %>%
summarise(y = mean(y, na.rm = TRUE), .groups = "drop") %>%
filter(month %in% y_m_list)
y_raw <- y_df$y
y_ratio <- c(1, y_raw[-1] / y_raw[-length(y_raw)])
y_center <- mean(y_ratio, na.rm = TRUE)
y_scale <- sd(y_ratio, na.rm = TRUE)
y <- (y_ratio - y_center) / y_scale
#EOD <- min(64, nrow(X_m)) # use up-to 2024-04 data points to select the important variables
EOD <- max(which(month_dates < as.Date("2024-07-01")))
sel <- select_topics(y, X_m, train_idx = 1:EOD, use_cor = FALSE, penalty_w = 0.1)
strong_idx <- match(sel$selected, colnames(X_m))
strong_idx <- strong_idx[!is.na(strong_idx)]
if (length(strong_idx) == 0) {
strong_idx <- 1
}
strong_idx
h_pred <- seq(5,12,1)
Res_m <- matrix(nrow = length(h_pred), ncol = 20)
for(k in seq_along(h_pred)){
h <- h_pred[k]
res_c <- NULL
test_idx <- (length(y) - h + 1):length(y)
obs_idx <- setdiff(seq_along(y), test_idx)
# AR
ar_base <- auto.arima(y[obs_idx],max.q = 0, D = 0,seasonal = FALSE, allowmean = FALSE, allowdrift = FALSE)
p1 <- max(1, ar_base$arma[1])
ar_fit <- arima(y[obs_idx], order = c(p1,0,0), include.mean = FALSE)
ar_prediction <- predict(ar_fit, n.ahead = h)$pred
res_c <- c(res_c, sqrt(mean((ar_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(ar_prediction) !=sign(y[test_idx])))
#random walk
mean_prediction <- rep(y[max(obs_idx)], length(test_idx))
res_c <- c(res_c, sqrt(mean((mean_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(mean_prediction) !=sign(y[test_idx])))
#Average
ave_prediction <- Average_prediction(y[obs_idx], length(test_idx))
res_c <- c(res_c, sqrt(mean((ave_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(ave_prediction) !=sign(y[test_idx])))
#AR + unemployment
ar_unem_base <- auto.arima(y[obs_idx], xreg = unem[obs_idx], max.q = 0, D = 0,seasonal = FALSE, allowmean = FALSE,      allowdrift = FALSE)
p1_un <- max(1, ar_unem_base$arma[1])
ar_unem_fit <- arima(y[obs_idx], xreg = unem[obs_idx], order = c(p1_un,0,0), include.mean = FALSE)
ar_unem_prediction <- predict(ar_unem_fit, newxreg = unem[test_idx], n.ahead = h)$pred
res_c <- c(res_c, sqrt(mean((ar_unem_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(ar_unem_prediction) !=sign(y[test_idx])))
#AR + LDA embedding
arx_fit <- arima(y[obs_idx], order = c(p1,0,0), xreg = X_m[obs_idx,strong_idx, drop = FALSE], include.mean = FALSE)
arx_predictions <- predict(arx_fit, n.ahead = h, newxreg = X_m[test_idx,strong_idx, drop = FALSE])$pred
res_c <- c(res_c, sqrt(mean((arx_predictions-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(arx_predictions) !=sign(y[test_idx])))
# AR + unem + LDA embedding
arx_unem_fit <- arima(y[obs_idx],order = c(p1,0,0), xreg = cbind(X_m[obs_idx,strong_idx, drop=FALSE],unem[obs_idx]), include.mean = FALSE)
arx_unem_predictions <- predict(arx_unem_fit, n.ahead=h, newxreg=cbind(X_m[test_idx,strong_idx,drop=FALSE],  unem[test_idx]))$pred
res_c <- c(res_c, sqrt(mean((arx_unem_predictions-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(arx_unem_predictions) !=sign(y[test_idx])))
# LLM powered: lag term + LDA embedding
p2=1
powered_prediction <- LLM_TS.Predict(X_m, y, tilde_y_m, p1, p2, obs_idx, test_idx, strong_idx, h)
res_c <- c(res_c, sqrt(mean((powered_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(powered_prediction) !=sign(y[test_idx])))
# LLM powered: lag term + unem + LDA embedding
powered_unem_prediction <- LLM_TS.Predict(cbind(X_m,unem), y, tilde_y_m, p1, p2, obs_idx, test_idx,
c(strong_idx,ncol(X_m)+1), h)
res_c <- c(res_c, sqrt(mean((powered_unem_prediction-y[test_idx])^2)))
res_c <- c(res_c, mean(sign(powered_unem_prediction) !=sign(y[test_idx])))
# TimeLLM (CPI only) - not available for WSJ yet
res_c <- c(res_c, NA_real_, NA_real_)
# PatchTST (CPI only) - not available for WSJ yet
res_c <- c(res_c, NA_real_, NA_real_)
Res_m[k,] <- res_c
}
LDA_mse <- Res_m[,seq(1, ncol(Res_m), 2)]
LDA_sign <- Res_m[,seq(2, ncol(Res_m), 2)]
colnames(LDA_mse) <- c('AR','RW','AVE','AR+unem','LDA','LDA+unem','LLM+LDA','LLM+LDA+unem',
'TimeLLM','PatchTST')
colnames(LDA_sign) <- c('AR','RW','AVE','AR+unem','LDA','LDA+unem','LLM+LDA','LLM+LDA+unem',
'TimeLLM','PatchTST')
MSE_without_unem <- LDA_mse[,c('AR','RW','AVE','LDA','LLM+LDA','TimeLLM','PatchTST')]
rMSE_without_unem <- sweep(MSE_without_unem, 1, MSE_without_unem[,'AR',drop=FALSE], "/")
rMSE_without_unem <- cbind(h_pred, rMSE_without_unem)
knitr::kable(rMSE_without_unem,col.names = c('H','AR','RW','AVE','LDA','LLM+LDA','TimeLLM','PatchTST'), digits = 3, caption = 'Cumulative rPMSE without unemployment rate')
colMeans(rMSE_without_unem[,-1, drop = FALSE])
Sign_without_unem <- LDA_sign[,c('AR','RW','AVE','LDA','LLM+LDA','TimeLLM','PatchTST')]
rSign_without_unem <- sweep(Sign_without_unem, 1, Sign_without_unem[,'AR',drop=FALSE], "/")
rSign_without_unem <- cbind(h_pred, rSign_without_unem)
knitr::kable(rSign_without_unem,col.names = c('H','AR','RW','AVE','LDA','LLM+LDA','TimeLLM','PatchTST'), digits = 3, caption = 'Cumulative rSign without unemployment rate')
colMeans(rSign_without_unem[,-1, drop = FALSE])
MSE_with_unem <- LDA_mse[,c('AR+unem','RW','AVE','LDA+unem','LLM+LDA+unem')]
rMSE_with_unem <- sweep(MSE_with_unem, 1, MSE_with_unem[,'AR+unem',drop=FALSE], "/")
rMSE_with_unem <- cbind(h_pred, rMSE_with_unem)
knitr::kable(rMSE_with_unem,col.names = c('H','AR+unem','RW','AVE','LDA+unem','LLM+LDA+unem'), digits = 3, caption = 'Cumulative rPMSE with unemployment rate')
colMeans(rMSE_with_unem[,-1, drop = FALSE])
Sign_with_unem <- LDA_sign[,c('AR+unem','RW','AVE','LDA+unem','LLM+LDA+unem')]
rSign_with_unem <- sweep(Sign_with_unem, 1, Sign_with_unem[,'AR+unem',drop=FALSE], "/")
rSign_with_unem <- cbind(h_pred, rSign_with_unem)
knitr::kable(rSign_with_unem,col.names = c('H','AR+unem','RW','AVE','LDA+unem','LLM+LDA+unem'), digits = 3, caption = 'Cumulative rSign with unemployment rate')
colMeans(rSign_with_unem[,-1, drop = FALSE])
?qt
suppressPackageStartupMessages({
library(dplyr)
library(ggplot2)
library(lubridate)
library(readr)
})
source("utility.R")
set.seed(1234)
# Load BERT embedding dataset (same schema as BERT analysis)
df_raw <- read.csv("wsj_mean_inflation_predictions_withBERT_vector.csv",
check.names = FALSE, stringsAsFactors = FALSE)
setwd("/Users/sunao/Desktop/LLM-TS-Revision/code-final/WSJ-plot")
suppressPackageStartupMessages({
library(dplyr)
library(ggplot2)
library(lubridate)
library(readr)
})
source("utility.R")
set.seed(1234)
# Load BERT embedding dataset (same schema as BERT analysis)
df_raw <- read.csv("wsj_mean_inflation_predictions_withBERT_vector.csv",
check.names = FALSE, stringsAsFactors = FALSE)
# Identify topic columns (numeric or X-prefixed)
topic_cols <- names(df_raw)[grepl("^cls_\\d+$|^topic_\\d+$|^X\\d+$|^\\d+$", names(df_raw))]
if (length(topic_cols) == 0) {
stop("No topic columns found in wsj_mean_inflation_predictions_withBERT_vector.csv")
}
# Preprocess to monthly/period structure
df_new <- df_raw %>%
mutate(
date = as.Date(date),
month = format(date, "%Y-%m"),
day = day(date),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
) %>%
dplyr::select(month, period, pred_score, all_of(topic_cols))
df_summary <- df_new %>%
group_by(month, period) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
y_m_list <- sort(unique(df_summary$month))
month_dates <- as.Date(paste0(y_m_list, "-01"))
# Topic matrix: monthly averages (scaled)
topic_cols_summary <- intersect(topic_cols, names(df_summary))
X_m <- df_summary %>%
group_by(month) %>%
summarise(across(all_of(topic_cols_summary), ~ mean(.x, na.rm = TRUE)), .groups = "drop") %>%
arrange(month) %>%
dplyr::select(-month) %>%
as.matrix()
X_m <- scale(X_m)
# Pred score monthly mean (scaled)
y <- df_new %>%
group_by(month) %>%
summarise(y = mean(pred_score, na.rm = TRUE), .groups = "drop") %>%
arrange(month) %>%
pull(y)
y <- scale(y)
# Match BERT selection window
EOD <- max(which(month_dates < as.Date("2024-06-01")))
train_idx <- 1:EOD
# Run the same LLM-TS selection procedure
sel <- tryCatch(
select_topics(y, X_m, train_idx = train_idx, use_cor = FALSE, penalty_w = 10),
error = function(e) list(selected = character())
)
selected_topics <- sel$selected
# Correlations between AR residuals and each topic (train window)
ar_base <- auto.arima(y[train_idx], max.q = 0, D = 0, seasonal = FALSE,
allowmean = FALSE, allowdrift = FALSE)
p_ar <- ar_base$arma[1]
ar_fit <- arima(y[train_idx], order = c(p_ar, 0, 0), include.mean = FALSE)
resid_base <- residuals(ar_fit)
cor_scores <- sapply(colnames(X_m), function(col) {
cor(resid_base, X_m[train_idx, col], use = "complete.obs")
})
score_df <- data.frame(
topic = colnames(X_m),
abs_cor = abs(cor_scores),
selected = colnames(X_m) %in% selected_topics,
stringsAsFactors = FALSE
)
# Boxplot of absolute correlations with highlighted selected topics
p <- ggplot(score_df, aes(x = "All topics", y = abs_cor)) +
geom_boxplot(outlier.shape = NA, fill = "grey90", color = "grey40") +
geom_jitter(aes(color = selected), width = 0.2, alpha = 0.4, size = 1.8) +
geom_point(data = subset(score_df, selected), aes(y = abs_cor), color = "#d95f02", size = 3) +
labs(
x = NULL,
y = "|Correlation| with AR residuals",
color = "LLM-TS selected",
title = NULL
) +
scale_color_manual(values = c(`TRUE` = "#d95f02", `FALSE` = "grey50")) +
theme_minimal() +
theme(
legend.position = "top",
plot.title = element_blank()
)+coord_flip()
p
selected_topics
setwd("/Users/sunao/Desktop/LLM-TS-Revision/code-final/WSJ-BERT")
setwd("/Users/sunao/Desktop/LLM-TS-Revision/code-final/WSJ-plot")
suppressPackageStartupMessages({
library(dplyr)
library(ggplot2)
library(lubridate)
library(readr)
})
source("utility.R")
set.seed(1234)
# Load BERT embedding dataset (same schema as BERT analysis)
df_raw <- read.csv("wsj_mean_inflation_predictions_withBERT_vector.csv",
check.names = FALSE, stringsAsFactors = FALSE)
# Match BERT.Rmd target
target_var <- "CPIMEDSL"
macro_raw <- read.csv("./2025-10-MD.csv", stringsAsFactors = FALSE, check.names = FALSE)
macro_raw$sasdate <- suppressWarnings(as.Date(macro_raw[[1]], format = "%m/%d/%Y"))
macro_raw <- macro_raw[!is.na(macro_raw$sasdate), ]
# Identify topic columns (BERT.Rmd excludes cls_0)
topic_cols <- names(df_raw)[grepl("^cls_\\d+$", names(df_raw))]
if (length(topic_cols) == 0) {
stop("No topic columns found in wsj_mean_inflation_predictions_withBERT_vector.csv")
}
# Preprocess to monthly/period structure
df <- df_raw %>%
mutate(date = as.Date(date)) %>%
filter(date < as.Date("2025-09-01"), date > as.Date("2015-08-31")) %>%
arrange(date) %>%
mutate(
month = format(date, "%Y-%m"),
day = day(date),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
)
df_summary <- df %>%
group_by(month, period) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
y_m_list <- sort(unique(df_summary$month))
month_dates <- as.Date(paste0(y_m_list, "-01"))
# Topic matrix: monthly averages (scaled)
X_m <- matrix(ncol = length(topic_cols), nrow = length(y_m_list))
for (i in seq_along(y_m_list)) {
res_ym <- y_m_list[i]
X_m[i, ] <- apply(df_summary[df_summary$month == res_ym, topic_cols], 2, mean)
}
X_m <- scale(X_m)
colnames(X_m) <- topic_cols
topic_dates <- df$date
topic_months <- df$month
m_dates <- macro_raw$sasdate
if (!target_var %in% names(macro_raw)) {
stop(paste("Target variable not found in 2025-10-MD.csv:", target_var))
}
m_vals <- macro_raw[[target_var]]
ptr <- 1
current <- NA_real_
target_series <- numeric(length(topic_dates))
for (i in seq_along(topic_dates)) {
t_d <- topic_dates[i]
while (ptr <= length(m_dates) && m_dates[ptr] <= t_d) {
current <- m_vals[ptr]
ptr <- ptr + 1
}
target_series[i] <- current
}
y_df <- data.frame(month = topic_months, y = target_series) %>%
group_by(month) %>%
summarise(y = mean(y, na.rm = TRUE), .groups = "drop") %>%
filter(month %in% y_m_list)
y_raw <- y_df$y
y_ratio <- c(1, y_raw[-1] / y_raw[-length(y_raw)])
y_center <- mean(y_ratio, na.rm = TRUE)
y_scale <- sd(y_ratio, na.rm = TRUE)
y <- (y_ratio - y_center) / y_scale
# Match BERT selection window
EOD <- max(which(month_dates < as.Date("2024-06-01")))
train_idx <- 1:EOD
# Run the same LLM-TS selection procedure
sel <- tryCatch(
select_topics(y, X_m, train_idx = train_idx, use_cor = FALSE, penalty_w = 10),
error = function(e) list(selected = character())
)
selected_topics <- sel$selected
selected_topics
# Correlations between AR residuals and each topic (train window)
ar_base <- auto.arima(y[train_idx], max.q = 0, D = 0, seasonal = FALSE,
allowmean = FALSE, allowdrift = FALSE)
p_ar <- ar_base$arma[1]
ar_fit <- arima(y[train_idx], order = c(p_ar, 0, 0), include.mean = FALSE)
resid_base <- residuals(ar_fit)
cor_scores <- sapply(colnames(X_m), function(col) {
cor(resid_base, X_m[train_idx, col], use = "complete.obs")
})
score_df <- data.frame(
topic = colnames(X_m),
abs_cor = abs(cor_scores),
selected = colnames(X_m) %in% selected_topics,
stringsAsFactors = FALSE
)
# Boxplot of absolute correlations with highlighted selected topics
p <- ggplot(score_df, aes(x = "All topics", y = abs_cor)) +
geom_boxplot(outlier.shape = NA, fill = "grey90", color = "grey40") +
geom_jitter(aes(color = selected), width = 0.2, alpha = 0.4, size = 1.8) +
geom_point(data = subset(score_df, selected), aes(y = abs_cor), color = "#d95f02", size = 3) +
labs(
x = NULL,
y = "|Correlation| with AR residuals",
color = "LLM-TS selected",
title = NULL
) +
scale_color_manual(values = c(`TRUE` = "#d95f02", `FALSE` = "grey50")) +
theme_minimal() +
theme(
legend.position = "top",
plot.title = element_blank()
)+coord_flip()
p
library(dplyr)
library(forecast)
library(MTS)
library(lubridate)
library(ggplot2)
# Load WSJ topics with prediction scores
data_path <- "topics_with_pred_score_final.csv"
df_raw <- read.csv(data_path, stringsAsFactors = FALSE, check.names = FALSE)
df <- df_raw %>%
mutate(date = as.Date(date)) %>%
arrange(date)
# Build within-month periods
df_period <- df %>%
mutate(
month = format(date, "%Y-%m"),
day = day(date),
period = case_when(
day <= 10 ~ "up",
day <= 20 ~ "middle",
TRUE ~ "down"
)
) %>%
dplyr::select(-date)
df_summary <- df_period %>%
group_by(month, period) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE)), .groups = "drop")
period_levels <- c("up", "middle", "down")
complete_months <- df_summary %>%
count(month) %>%
filter(n == length(period_levels)) %>%
pull(month)
y_m_list <- sort(complete_months)
df_summary <- df_summary %>% filter(month %in% complete_months)
# Matrix of pred_score by month-period (3 columns: up/middle/down)
tilde_y_m <- matrix(ncol = length(period_levels), nrow = length(y_m_list))
for (i in seq_along(y_m_list)) {
res_ym <- y_m_list[i]
rows <- df_summary %>%
filter(month == res_ym) %>%
arrange(factor(period, levels = period_levels))
if (nrow(rows) != length(period_levels)) {
stop(sprintf("Month %s missing period rows; found %s", res_ym, nrow(rows)))
}
tilde_y_m[i, ] <- rows$pred_score
}
# Topic feature matrix averaged across periods each month
topic_cols <- names(df_summary)[grepl("^topic_\\d+$", names(df_summary))]
if (length(topic_cols) == 0) {
stop("Topic columns missing from data.")
}
X_m <- matrix(ncol = length(topic_cols), nrow = length(y_m_list))
for (i in seq_along(y_m_list)) {
res_ym <- y_m_list[i]
X_m[i, ] <- df_summary %>%
filter(month == res_ym) %>%
dplyr::select(all_of(topic_cols)) %>%
summarise(across(everything(), ~ mean(.x, na.rm = TRUE))) %>%
unlist(use.names = FALSE)
}
# Monthly CPI target
y_df <- df_period %>%
group_by(month) %>%
summarise(y = mean(CPIAUCSL, na.rm = TRUE), .groups = "drop") %>%
filter(!is.na(y)) %>%
arrange(month)
# Align months across y, tilde_y_m, and X_m
common_months <- intersect(y_m_list, y_df$month)
month_filter <- match(common_months, y_m_list)
tilde_y_m <- tilde_y_m[month_filter, , drop = FALSE]
X_m <- X_m[month_filter, , drop = FALSE]
y_df <- y_df %>% filter(month %in% common_months) %>%
arrange(match(month, common_months))
y_m_list <- common_months
y <- y_df$y
y <- as.numeric(scale(y))
h <- 5
test_idx <- (length(y) - h + 1):length(y)
obs_idx <- setdiff(seq_along(y), test_idx)
ar_fit <- auto.arima(
y[obs_idx],
max.q = 0,
D = 0,
seasonal = FALSE,
allowmean = FALSE,
allowdrift = FALSE
)
p_use <- max(1, ar_fit$arma[1])
ar_fit <- arima(y[obs_idx], order = c(p_use, 0, 0), include.mean = FALSE)
strong_idx <- order(abs(cov(ar_fit$residuals, X_m[obs_idx, ])), decreasing = TRUE)[1:2]
arx_fit <- tryCatch(
arima(y[obs_idx], order = c(p_use, 0, 0), xreg = X_m[obs_idx, strong_idx], include.mean = FALSE),
error = function(e) {
arima(y[obs_idx], order = c(1, 0, 0), xreg = X_m[obs_idx, strong_idx], include.mean = FALSE)
}
)
arx_predictions <- predict(arx_fit, n.ahead = h, newxreg = X_m[test_idx, strong_idx])$pred
tilde_y_fit <- VARX(zt = tilde_y_m, p = 1, xt = X_m[, strong_idx], m = 0, include.mean = FALSE)
tilde_y_residual_m <- tilde_y_fit$residuals[obs_idx, ]
combined_data <- bind_rows(
data.frame(x = as.numeric(arx_fit$residuals), y = as.numeric(tilde_y_residual_m[, 1]), group = "First"),
data.frame(x = as.numeric(arx_fit$residuals), y = as.numeric(tilde_y_residual_m[, 2]), group = "Middle"),
data.frame(x = as.numeric(arx_fit$residuals), y = as.numeric(tilde_y_residual_m[, 3]), group = "Last")
)
combined_data$group <- factor(combined_data$group, levels = c("First", "Middle", "Last"))
remove_outliers <- function(data, x_col, y_col, prob = 0.975) {
coords <- data %>%
dplyr::select(all_of(c(x_col, y_col))) %>%
na.omit()
if (nrow(coords) == 0) {
return(data)
}
center <- colMeans(coords)
cov_mat <- cov(coords)
# Regularize in case covariance is singular
cov_mat <- cov_mat + diag(1e-6, nrow = 2)
dist2 <- mahalanobis(coords, center = center, cov = cov_mat)
cutoff <- qchisq(prob, df = 2)
data %>%
mutate(keep_flag = dist2 <= cutoff) %>%
filter(keep_flag) %>%
dplyr::select(-keep_flag)
}
combined_data_cleaned <- combined_data %>%
group_by(group) %>%
group_modify(~ remove_outliers(.x, "x", "y"))
band_x <- max(bw.nrd(combined_data_cleaned$x), 0.1)
band_y <- max(bw.nrd(combined_data_cleaned$y), 0.1)
band_width <- c(band_x * 3, band_y * 3)
p <- ggplot(combined_data_cleaned, aes(x = x, y = y)) +
stat_density_2d(aes(color = after_stat(level)), linewidth = 1, h = band_width) +
geom_point(alpha = 0.3, color = "blue") +
scale_color_viridis_c() +
facet_wrap(~group, ncol = 3) +
labs(x = "LLM inflation index", y = "CPI", color = "Density level") +
xlim(-.3, .3) + ylim(-.4, .4) +
theme_minimal()
p
ggsave("error_density_plot.png", p, width = 10, height = 4, dpi = 300)
